#!/bin/env python3
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import os
import psutil
import gc
from mpi4py import MPI
import math

def get_memory_usage():
    """获取当前进程的内存使用情况"""
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024  # 转换为MB

# 初始化MPI
comm = MPI.COMM_WORLD
rank = comm.Get_rank()
size = comm.Get_size()

# 计算位移
def calculate_displacement(pos_initial, pos_final):
    displacement = pos_final - pos_initial
    return displacement

# 读取指定序数的原子的平衡位置
def read_poscar(filename, atom_index):
    """读取指定序数的原子的平衡位置"""
    try:
        with open(filename, 'r') as f:
            lines = f.readlines()

        lattice_constants = float(lines[1])
        lattice_vectors = np.array([list(map(float, line.split())) for line in lines[2:5]])
        elements = lines[5].split()
        atom_counts = list(map(int, lines[6].split()))

        num_atoms = sum(atom_counts)
        if atom_index >= num_atoms:
            raise ValueError(f"原子索引 {atom_index} 超出范围 (0-{num_atoms-1})")

        positions = np.array([list(map(float, line.split()[:3])) for line in lines[8:8+num_atoms]])
        position = positions[atom_index]

        return lattice_constants, lattice_vectors, elements, atom_counts, position
    except Exception as e:
        print(f"读取POSCAR文件时出错: {str(e)}")
        raise

def process_xdatcar_chunk(lines, num_atoms, chunk_size=1000):
    """处理XDATCAR文件的一个数据块"""
    positions = []
    step_size = num_atoms + 1  # 每个时间步的行数（1行Direct + num_atoms行原子位置）
    
    for i in range(0, len(lines), step_size):
        if i + step_size > len(lines):
            break
        # 跳过Direct行，只读取原子位置
        positions_step = np.array([list(map(float, line.split())) for line in lines[i+1:i+step_size]])
        positions.append(positions_step)
        if len(positions) >= chunk_size:
            yield np.array(positions)
            positions = []
    if positions:
        yield np.array(positions)

def read_xdatcar(filename, atom_index, chunk_size=1000):
    """读取指定序数原子在全过程的位置，使用生成器方式"""
    try:
        with open(filename, 'r') as f:
            # 读取文件头（前7行）
            for _ in range(6):
                next(f)
            
            # 获取原子数量（第7行）
            atom_counts = list(map(int, next(f).split()))
            num_atoms = sum(atom_counts)
            step_size = num_atoms + 1  # 每个时间步的行数（1行Direct + num_atoms行原子位置）
            
            # 使用生成器处理数据
            chunk_lines = []
            for line in f:
                chunk_lines.append(line)
                # 每step_size行为一个时间步
                if len(chunk_lines) >= step_size * chunk_size:
                    for chunk in process_xdatcar_chunk(chunk_lines, num_atoms, chunk_size):
                        yield chunk[:, atom_index]
                    chunk_lines = []
                    gc.collect()  # 手动触发垃圾回收
            
            # 处理剩余数据
            if chunk_lines:
                for chunk in process_xdatcar_chunk(chunk_lines, num_atoms, chunk_size):
                    yield chunk[:, atom_index]
                    
    except Exception as e:
        print(f"读取XDATCAR文件时出错: {str(e)}")
        raise

def write_poscar_avg(filename, lattice_constants, lattice_vectors, elements, atom_counts, positions):
    """写入平均位置到POSCAR文件"""
    try:
        with open(filename, 'w') as f:
            f.write("generated by positions.py\n")
            f.write(f"    {lattice_constants}\n")
            for vec in lattice_vectors:
                f.write(f"    {vec[0]:20.16f} {vec[1]:20.16f} {vec[2]:20.16f}\n")
            f.write(" ".join(elements) + "\n")
            f.write(" ".join(map(str, atom_counts)) + "\n")
            f.write("Direct\n")
            for pos in positions:
                f.write(f"{pos[0]:20.16f} {pos[1]:20.16f} {pos[2]:20.16f}\n")
    except Exception as e:
        print(f"写入POSCAR文件时出错: {str(e)}")
        raise

def process_atom_chunk(atom_indices, poscar_file, xdatcar_file, chunk_size=1000):
    """处理一组原子的平均位置计算"""
    results = []
    for atom_index in atom_indices:
        # 读取初始位置
        _, _, _, _, pos_initial = read_poscar(poscar_file, atom_index)
        
        # 初始化累积变量
        total_displacement = np.zeros(3)
        count = 0
        
        # 使用生成器处理XDATCAR数据
        for positions_chunk in read_xdatcar(xdatcar_file, atom_index, chunk_size):
            # 计算位移
            displacements = calculate_displacement(pos_initial, positions_chunk)
            
            # 处理周期性边界条件
            for i in range(3):
                mask = displacements[:, i] > 0.5
                displacements[mask, i] -= 1.0
            
            # 累积位移
            total_displacement += np.sum(displacements, axis=0)
            count += len(displacements)
            
            # 定期清理内存
            if count % (chunk_size * 10) == 0:
                gc.collect()
        
        # 计算平均位移
        avg_displacement = total_displacement / count
        
        # 应用阈值
        avg_displacement[np.abs(avg_displacement) < 0.00001] = 0
        
        # 计算平均位置
        avg_position = pos_initial + avg_displacement
        avg_position %= 1.0
        results.append((atom_index, avg_position))
        
        # 打印内存使用情况
        if atom_index % 100 == 0:
            print(f"进程 {rank}: 处理原子 {atom_index}, 内存使用: {get_memory_usage():.2f} MB")
    
    return results

def main():
    # 文件路径
    poscar_file = "POSCAR"
    xdatcar_file = "XDATCAR"
    output_file = "POSCAR_AVG"
    chunk_size = 1000  # 每次处理的数据块大小

    if rank == 0:
        print(f"初始内存使用: {get_memory_usage():.2f} MB")
        print(f"使用 {size} 个进程进行并行计算")

    # 读取初始结构信息
    lattice_constants, lattice_vectors, elements, atom_counts, _ = read_poscar(poscar_file, 0)
    num_atoms = sum(atom_counts)
    
    # 计算每个进程处理的原子数量
    atoms_per_process = math.ceil(num_atoms / size)
    start_idx = rank * atoms_per_process
    end_idx = min((rank + 1) * atoms_per_process, num_atoms)
    local_atom_indices = list(range(start_idx, end_idx))
    
    # 处理本地原子
    local_results = process_atom_chunk(local_atom_indices, poscar_file, xdatcar_file, chunk_size)
    
    # 收集所有结果
    all_results = comm.gather(local_results, root=0)
    
    if rank == 0:
        # 合并结果
        avg_positions = [None] * num_atoms
        for process_results in all_results:
            for atom_index, position in process_results:
                avg_positions[atom_index] = position
        
        # 写入结果
        write_poscar_avg(output_file, lattice_constants, lattice_vectors, elements, atom_counts, avg_positions)
        print(f"计算完成，结果已保存到 {output_file}")
        print(f"最终内存使用: {get_memory_usage():.2f} MB")

if __name__ == "__main__":
    main()
